# This file is automatically @generated by Poetry and should not be changed by hand.

[[package]]
name = "py4j"
version = "0.10.9.9"
description = "Enables Python programs to dynamically access arbitrary Java objects"
category = "main"
optional = false
python-versions = "*"
files = [
    {file = "py4j-0.10.9.9-py2.py3-none-any.whl", hash = "sha256:c7c26e4158defb37b0bb124933163641a2ff6e3a3913f7811b0ddbe07ed61533"},
    {file = "py4j-0.10.9.9.tar.gz", hash = "sha256:f694cad19efa5bd1dee4f3e5270eb406613c974394035e5bfc4ec1aba870b879"},
]

[[package]]
name = "pyspark"
version = "4.0.1"
description = "Apache Spark Python API"
category = "main"
optional = false
python-versions = ">=3.9"
files = [
    {file = "pyspark-4.0.1.tar.gz", hash = "sha256:9d1f22d994f60369228397e3479003ffe2dd736ba79165003246ff7bd48e2c73"},
]

[package.dependencies]
py4j = "0.10.9.9"

[package.extras]
connect = ["googleapis-common-protos (>=1.65.0)", "grpcio (>=1.67.0)", "grpcio-status (>=1.67.0)", "numpy (>=1.21)", "pandas (>=2.0.0)", "pyarrow (>=11.0.0)"]
ml = ["numpy (>=1.21)"]
mllib = ["numpy (>=1.21)"]
pandas-on-spark = ["numpy (>=1.21)", "pandas (>=2.0.0)", "pyarrow (>=11.0.0)"]
sql = ["numpy (>=1.21)", "pandas (>=2.0.0)", "pyarrow (>=11.0.0)"]

[metadata]
lock-version = "2.0"
python-versions = "^3.11"
content-hash = "354f12207f05ca497eb0536e7bb284028c46f49f94817e0005ae8d91c61b5f4b"
